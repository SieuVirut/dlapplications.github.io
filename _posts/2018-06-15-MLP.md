---
layout: post
title: Deep learning cơ bản (phần 2)
subtitle: Nền tảng của deep learning - Multi-layer Perceptron
tags: [beginner, MLP]
math: true
---
# Nền tảng của deep learning - Multi-layer Perceptron
### Mục lục:
1. [Mở đầu](#intro)
2. [Kí hiệu](#notation )
3. [Từ input tới output ](#forward)
4. [Cách train một MLP cho bài toán binary classification](#train)
    1. [Loss Function](#loss)
    2. [Gradient Descent](#GD)    


### 1. Mở đầu <a name="intro"></a>
Ở [phần 1](https://dlapplications.github.io/2018-06-11-perceptron/) của series, chúng ta đã tìm hiểu về perceptron - mô hình đơn giản nhất của một artificial neuron (tế bào thần kinh nhân tạo). Trong phần tiếp theo này, nhóm sẽ giới thiệu tới các bạn mô hình đơn giản nhất của một Artifial Neural Network (ANN: mạng thần kinh nhân tạo) được xây dựng nên từ các perceptron này. Mô hình này có tên là Multi-layer Perceptron (MLP) và thường được biểu diễn như hình dưới.<br/>
![ANN](/img/20180611/ANN.jpg) 
> Hình 1. Multi-layer Perceptron

Gọi là Multi-layer Perceptron (perceptron nhiều lớp) bởi vì nó là tập hợp của các perceptron được sắp xếp thành nhiều hơn 2 lớp. Trong hình trên ta có một ANN với 3 lớp: Input layer (lớp đầu vào), Output layer (lớp đầu ra) và Hidden layer (lớp ẩn). Vì khi giải quyết một bài toán người dùng cuối thường chỉ quan tâm đến input và output của một mô hình, do vậy trong ANN ngoài lớp Input và Output ra thì các lớp neuron ở giữa được gọi chung là Hidden (ẩn: không phải là không nhìn thấy mà đơn giản là không quan tâm đến). 
### 2. Kí hiệu <a name="notation"></a>
Để dễ hình dung, người ta thường gọi lớp Input là lớp thứ nhất (kí hiệu $l=1$) cứ thế tăng dần cho tới lớp output (trong Hình 1 là $l=3$). Ta sẽ nói ANN này có số lớp là $L=3$. Mỗi hình tròn là biểu trưng cho một neuron do đó đối với lớp thứ 2 ta nói nó có $n=5$ neuro, lớp thứ 3 có $n=2$ neuron. Đối với lớp input thì mỗi hình tròn chỉ là đại diện cho một giá trị input chứ không phải là một neuron. Để biểu diễn một ANN bằng công thức toán, người ta thường sử dụng các kí hiệu như sau:
+ Các giá trị input thường được kí hiệu là $x_1, x_2, x_3, ..., x_{n_x}$ với ANN có $n_x$ input. 
+ Đối với từng neuron, giá trị output của neuron thứ $k$ của lớp thứ $l$ được kí hiệu là $a_{k}^{l}$. Ví dụ output của neuron thứ 1 (tính từ trên xuống) của lớp thứ 2 sẽ là $a_{1}^{(2)}$, phía trên sẽ là số thứ tự lớp phía dưới là thứ tự neuron. Ngoài lớp Input ra thì ta có thể dễ dàng thấy là output của lớp này sẽ là input cho lớp kế tiếp.
+ Như đã giới thiệu ở bài trước, mỗi mũi tên nối giữa input và các neuron cũng như giữa các neuron của 2 lớp liền kề nhau đại diện cho một liên kết với độ mạnh yếu được quyết định bởi một giá trị $w$ (weight). Ta gọi giá trị $w$ của liên kết giữa neuron thứ $k$ ở lớp thứ $l-1$ với neuron thứ $j$ ở lớp kế tiếp $l$ là $w_{jk}^{(l)}$. Chỗ này rất dễ nhầm lẫn nên các bạn chú ý, ví dụ liên kết giữa neuron thứ 1 ở lớp thứ 2 với neuron thứ 2 ở lớp thứ 3 sẽ viết là $w_{21}^{(3)}$, ở phía trên là thứ tự lớp của neuron nhận tín hiệu vào, phía dưới là thứ tự của các neuron trong lớp với neuron nhận tín hiệu viết trước và neuron gửi tín hiệu viết sau.  
+ Cuối cùng, các giá trị ouput được kí hiệu là $\hat{y_1}, \hat{y_2}, ..., \hat{y_{n_y}}$ với $n_y$ là số output.

### 3. Từ input tới output <a name="forward"></a>
![ANN](/img/20180611/ANN.jpg) 

Sử dụng các kí hiệu như trên chúng ta sẽ biểu diễn quá trình tính toán từ input cho ra output của một MLP 3 lớp trong Hình 1. Với lớp $l=1$ thì chỉ là lớp của các giá trị input nên ta không tính toán gì ở đây. Với lớp $l=2$ ta sẽ tính output của từng neuron. Bắt đầu với neuron thứ 1 của lớp $l=2$, như đã tìm hiểu ở [phần 1](https://dlapplications.github.io/2018-06-11-perceptron/) đầu tiên chúng ta sẽ tính tổng các input tới đã được điều chỉnh độ mạnh yếu nhờ các giá trị $w$ (gọi là $z$, cách kí hiệu giống như với $a$):

>$$
z_{1}^{(2)} = 1w_0 + w_{11}^{(2)}x_1 + w_{12}^{(2)}x_2 + w_{13}^{(2)}x_3 = \sum w_{jk}^{(l)}x_k + w_0
$$ 

Về giá trị $w_0$ (gọi là bias, do đó còn được kí hiệu là b) các bạn có thể xem lại ở [phần 1](). Ta đã biết nếu $z$ vượt qua một ngưỡng nhất định thì neuron sẽ phát ra một output còn không thì sẽ không output gì cả. Để quyết định một neuron có output hay không thì trong Deep Learning người ta sử dụng một số hàm số được gọi chung là Activation function. Nhóm sẽ giới thiệu kĩ hơn về các Activation function trong một dịp khác còn ở đây giả sử ta sử dụng một hàm số thông dụng là hàm Sigmoid như sau:
>$$
\sigma(z) = \frac{1}{1+e^{-z}} = \frac{e^z}{e^z+1}
$$  

![sigmoid](https://qph.fs.quoracdn.net/main-qimg-07066668c05a556f1ff25040414a32b7)<br/>
> Hình 2. Đồ thị của hàm số sigmoid 

Như ta thấy nếu $z$ nhỏ hơn một ngưỡng nhất định thì giá trị output của hàm sigmoid $\sigma$ (đọc là sigma) sẽ gần với 0 và nếu $z$ đủ lớn thì giá trị ouput sẽ gần với 1. Sử dụng hàm sigmoid này ta sẽ tính được giá trị output của neuron thứ 1 của lớp $l=2$ như sau:

>$$
a_{1}^{(2)} = \sigma(z_{1}^{(2)}) = \sigma(\sum w_{jk}^{(2)}x_k + w_0)
$$

Và ta có thể làm tương tự như vậy đối với các neuron tiếp theo trong lớp Hidden $l=2$ và lớp Output $l=3$. Ta có thể thấy các tính toán trên giống hệt nhau cho các neuron trong cùng một lớp và không có gì quá phức tạp. Vì lý do đó mà ta có thể tính toán song song (parallel) nhiều neuron trong một lớp để tăng tốc độ. Điều đó dẫn tới việc trong DL thì sử dụng GPU có tốc độ tính toán nhanh hơn nhiều so với CPU. Lý do là GPU có nhiều core hơn rất nhiều so với CPU nên phù hợp cho tính toán song song. Mặc dù mỗi core của GPU có tốc độ chậm hơn rất nhiều so với mỗi core của CPU nhưng với các tính toán đơn giản trên thì vẫn dư sức để chạy.<br/>
Để có thể áp dụng tính toán song song thì ta cần biểu diễn các tính toán trên theo một dạng khác. Nếu bạn nào đã học đại số tuyến tính thì thay vì viết $z_i$ là tổng của các $w_ix_i$ thì ta có thể biểu diễn thành tích vô hướng của hai vector như sau (bạn nào chưa hiểu thì có thể xem [link](https://vi.wikipedia.org/wiki/T%C3%ADch_v%C3%B4_h%C6%B0%E1%BB%9Bng) này):<br/>
>$$
  z_{1}^{(2)} =  
  \left[ {\begin{array}{cccc}
   w_{11}^{(2)} & w_{12}^{(2)} & w_{13}^{(2)} \\
  \end{array} } \right]
  \left[ {\begin{array}{c}
   x_1 \\
   x_2 \\
   x_3 
  \end{array} } \right] + b_{1}^{(2)}
  = W_{1}^{(2)T}X + b_{1}^{(2)}
$$

Trong đó, 
$$W_{1}^{(2)} = 
    \left[ {\begin{array}{c}
    w_{11}^{(2)} \\ 
    w_{12}^{(2)} \\ 
    w_{13}^{(2)}
    \end{array} } \right]
$$
và 
$$X = 
    \left[ {\begin{array}{c}
    x_{1} \\ x_{2} \\ x_{3}
    \end{array} } \right]
$$
lần lượt là cách viết theo dạng vector gồm tất cả các weight của neuron thứ 1 của lớp $l=2$ (ở đây ta thay $w_0$ bằng b để dễ phân biệt giữa weight và bias) và tất cả input. Do đó ta có thể viết gộp lại cách tính các giá trị output của tất cả các neuron trong lớp $l=2$ như sau:
>$$
    Z^{(2)} = 
        \left[ {\begin{array}{ccc}
        w_{11}^{(2)} & w_{12}^{(2)} & w_{13}^{(2)} \\
        w_{21}^{(2)} & w_{22}^{(2)} & w_{23}^{(2)} \\
        w_{31}^{(2)} & w_{32}^{(2)} & w_{33}^{(2)} \\
        w_{41}^{(2)} & w_{42}^{(2)} & w_{43}^{(2)} \\
        w_{51}^{(2)} & w_{52}^{(2)} & w_{53}^{(2)} 
        \end{array} } \right]
        \left[ {\begin{array}{c}
        x_1 \\
        x_2 \\
        x_3 
        \end{array} } \right] + 
        \left[ {\begin{array}{c}
        b_{1}^{(2)}  \\
        b_{2}^{(2)}  \\
        b_{3}^{(2)}  \\
        b_{4}^{(2)}  \\
        b_{5}^{(2)} 
        \end{array} } \right]
        = \left[ {\begin{array}{c}
        -W_{1}^{(2)T}- \\ 
        -W_{2}^{(2)T}- \\ 
        -W_{3}^{(2)T}- \\
        -W_{4}^{(2)T}- \\
        -W_{5}^{(2)T}- 
        \end{array} } \right]
        \left[ {\begin{array}{c}
        x_1 \\
        x_2 \\
        x_3 
        \end{array} } \right] +
        \left[ {\begin{array}{c}
        b_{1}^{(2)}  \\
        b_{2}^{(2)}  \\
        b_{3}^{(2)}  \\
        b_{4}^{(2)}  \\
        b_{5}^{(2)}   
        \end{array} } \right] 
        = W^{(2)T}X + b^{(2)}
$$

Ở đây, $W^{(2)}$ được gọi là weight matrix (ma trận) và $b^{(2)}$ là bias vector của lớp $l=2$. Trong ví dụ ta đang xét thì $W^{(2)}$ là ma trận có $3\times 5$ chiều (dimension), vector $X$ có 3 chiều, vector $b$ có 5 chiều (mỗi neuron có 1 bias) và vector $Z$ có 5 chiều. Các bạn có thể nhớ đơn giản số chiều của ma trận của $W^{(2)}$ là $3\times 5$ vì nó biến vector có chiều là 3 (có 3 input) thành vector có chiều là 5 (lớp hidden $l=2$ có 5 neuron). Tương tự, các bạn có thể đoán là ma trận $W^{(3)}$ của lớp output sẽ có số chiều là $5\times 2$ vì biến output của 5 neuron lớp hidden $l=2$ thành output của 2 neuron lớp output. Lưu ý là đầu vào cho 2 neuron ở lớp Output không phải là $Z^{(2)}$ mà là $A^{(2)}$ với: <br/>
>$$
A^{(2)} = \sigma (Z^{(2)}) = \sigma (W^{(2)T}X + b^{(2)})
$$

Tóm lại, toàn bộ các tính toán từ đầu vào cho tới đầu ra của một MLP 3 lớp như hình 1 có thể được tóm tắt như sau:
>$$
Z^{(2)} = W^{(2)T}X + b^{(2)}, \quad A^{(2)} = \sigma (Z^{(2)}) \\
Z^{(3)} = W^{(3)T}A^{(2)} + b^{(3)}, \quad \hat{Y} = A^{(3)} = f(Z^{(3)}) 
$$

Chính vì cách tính toán theo một chiều từ đầu vào cho tới đầu ra như trên mà đây còn được gọi là Feed-forward Neural Network (feedforward: truyền tới). 
Cần chú ý là đối với neuron ở lớp Output thì tùy vào output của bài toán mà ta sẽ chọn Activation function $f$ cho phù hợp. Lấy ví dụ với bài toán classification, với 2 output thì nếu neuron thứ nhất có giá trị đầu ra lớn hơn của neuron thứ 2 thì ta sẽ phân đối tượng vào class 1 (nhóm 1) còn ngược lại thì sẽ phân vào class 2 (nhóm 2). Đây được gọi là binary classification (phân loại nhị phân). Giả sử đối tượng không thể vừa thuộc class 1 vừa thuộc class 2 (chẳng hạn một con vật không thể vừa là chó vừa là mèo). Nếu ta gọi xác xuất mà mạng ANN của chúng ta dự đoán đối tượng $X$ thuộc class 1 là $P(Y=1|X)$ thì đồng nghĩa với mạng ANN cũng dự đoán xác xuất đối tượng thuộc class 2 là $P(Y=2|X) = 1-P(Y=1|X)$. Nghĩa là tổng xác xuất mà đối tượng thuộc một trong các class phải bằng 1 cho dù trong thực tế có thể đối tượng không thuộc class nào (vì model của chúng ta chỉ biết có từng ấy class). Để biểu diễn xác xuất này người ta thường sử dụng một hàm gọi là softmax làm activation cho lớp output. 
>$$
\hat{y_i} = softmax(z_{i}^{(3)}) = \frac{e^{z_i}}{\sum_{k=1}^{n_y} e^{z_k}}
$$

Lúc này vì tính chất của việc phân loại, output của một neuron $i$ không chỉ phụ thuộc vào tổng các input $z_i$ mà neuron đó nhận được mà còn phụ thuộc vào các giá trị $z$ của toàn bộ các neuron khác trong lớp. Các bạn có thể dễ dàng kiểm chứng mỗi output $y_i$ sẽ nằm trong khoảng từ $0\sim 1$ và tổng của tất cả output là 1. 
### 4. Cách train một MLP cho bài toán binary classification <a name="train"></a>
Ở trên, ta đã design một mạng ANN với 3 lớp MLP có 3 input và 2 output với softmax activation dành cho bài toán binary classification. Ví dụ cho một bài toán binary classification là chẳng hạn ta muốn biết kết quả đậu/rớt của một bạn học sinh thi vào Bách Khoa dựa trên điểm phẩy 3 năm 10, 11, 12 của bạn ấy. Giả sử để giải quyết bài toán này ta đã có một dataset gồm điểm phẩy 3 năm cấp ba của 1000 bạn thí sinh đã thi vào ĐHBK năm nay và kết quả đậu/rớt của các bạn ấy. Ở đây trong dataset mà ta có thì các bạn học sinh là đối tượng được phân loại, điểm phẩy của các bạn ấy được gọi là các **feature** (đặc điểm) của đối tượng và kết quả đậu hay rớt được gọi là **label** (nhãn). Ta quyết định dùng mạng ANN ở hình 1 để giải quyết bài toán này và sau khi train nó xong ta sẽ dùng nó để dự đoán cho các bạn thi các năm tiếp theo. <br/>
Vấn đề ở đây là ta phải tìm các giá trị weight $w$ thích hợp ở mỗi lớp sao cho mạng ANN của chúng ta có thể đưa ra các quyết định phân loại chính xác. Cách đơn giản nhất là đầu tiên ta sẽ gán các giá trị ngẫu nhiên cho mỗi weight $w$ và xem xem giá trị của output $y$ có chính xác hay không. Nếu $y$ không được như mong muốn thì ta sẽ lần lượt thử tăng giảm từng weight $w$ một và quan sát sự tăng giảm của $y$ xem có theo chiều hướng mà ta mong muốn không. Ta sẽ dừng quá trình thử và sai này lại khi mà các output $y$ cho tất cả các bạn học sinh đúng với kết quả thực trong data mà ta có. Nhưng với cách này có khi ta phải ngồi hàng giờ để so sánh từng output $y$ một cách thủ công với kết quả thực tế rồi tinh chỉnh từ weight một. Trong thời đại công nghiệp 4.0 này thì ta phải bắt máy tính làm những việc thủ công như vậy chứ không thì còn thời gian đâu mà xem youtube với cả lướt facebook nữa. Để làm được điều này thì ta phải làm 2 việc: (1) nói cho máy tính biết là nó sai bao nhiêu so với thực tế và (2) điều chỉnh tăng weight nào và giảm weight nào bao nhiêu để có kết quả gần với kết quả đúng hơn. Hai công đoạn này sẽ được tự động hóa nhờ vào **Loss function** và **Gradient Descent**.<br/>
#### 4.1 Loss function:<a name="loss"></a>
Ta nói cho máy tính biết output của nó sai nhiều hay ít so với kết quả trong data mà ta có nhờ vào một Loss fucntion (hàm mất mát) mà ở đó nếu giá trị của Loss function càng lớn nghĩa là máy tính sai càng nhiều. Đối với bài toán đậu/rớt ta đang xét thì nếu kết quả của một bạn thí sinh $A$ là đậu thì ta muốn mạng ANN của chúng ta sẽ có output của neuron thứ nhất càng cao hơn của neuron thứ hai càng tốt, nghĩa là dự đoán xác xuất đậu của bạn ấy cao hơn nhiều xác xuất rớt. Ta sẽ gọi neuron thứ nhất là neuron "đậu" và neuron thứ 2 là neuron "rớt". Đối với trường hợp đậu ta sẽ muốn vector output $\hat{y}$ gần với vector $[1, 0]$ và đối với trường hợp rớt thì là vector $[0, 1]$. Xét từng neuron thì ta có thể sử dụng một loss function như sau:<br/>
>$$
l_i = -(y_ilog(\hat{y_i}) + (1-y_i)log(1-\hat{y_i}))
$$

Ở đây thì $y_i$ là xác xuất trong thực tế (trong data) của việc đậu hay rớt (0 hoặc 1) còn $\hat{y_i}$ là xác xuất mà ANN của chúng ta dự đoán. Hàm số này được gọi là **Cross Entropy Loss**. Để hiểu rõ hơn cách hoạt động của loss funciton trên ta sẽ xét hai trường hợp sau đối với neuron "đậu" (neuron thứ 1):
1. ANN dự đoán đậu $\hat{y_1}>0.5$, kết quả thực tế là đậu $y_1=1$: ta sẽ có số hạng thứ 2 trong tổng $(1-y_1)log(1-\hat{y_1})=0$ do đó $l_1=-log(\hat{y_1})$. Khi xác xuất $\hat{y_1}$ càng lớn (càng gần với 1) thì loss $l_1$ sẽ càng nhỏ.
2. ANN dự đoán đậu $\hat{y_i}>0.5$, kết quả thực tế là rớt $y_i=0$: vì $y_1=0$ nên ta sẽ có số hạng thứ nhất trong tổng $y_1log(\hat{y_1})=0$ do đó $l_1=-log(1-\hat{y_1})$. Khi xác xuất $\hat{y_1}$ càng nhỏ (càng gần với 0) thì loss $l_1$ sẽ càng nhỏ.

Tương tự cho neuron "rớt", ta cũng sẽ có Loss function càng nhỏ khi kết quả dự đoán gần với kết quả thực của label. Trong thực tế ta sẽ không tính riêng loss cho từng neuron một mà tính tổng loss của tất cả các neuron.<br/> 
>$$
L = -\sum_{i=1}^{n_y}(y_ilog(\hat{y_i}) + (1-y_i)log(1-\hat{y_i}))
$$  


#### 4.2 Gradient Descent:<a name="GD"></a>
Vậy là ta đã biết cách để tự động hóa công đoạn nói cho máy tính biết nó sai nhiều hay ít. Việc tiếp theo là nói cho nó biết phải làm sao để Loss function càng nhỏ càng tốt. Ta có thể thấy Loss function của chúng ta là một hàm số của 3 biến là input $X$, weight $W$ và label $Y$ mà trong đó ta không thể thay đổi được $X$ và $Y$. Do vậy $W$ là các giá trị duy nhất mà ta có thể điều chỉnh để giảm loss xuống càng thấp càng tốt. Nói cách khác, lý tưởng nhất là với mọi $X$ và $Y$ ta tìm được các weight $W$ sao cho:<br/>
>$$
W^{\ast} = \operatorname*{arg\,min}_W L
$$

Kí hiệu trên có nghĩa $W^{\ast}$ là giá trị tối ưu (optimized) của weight mà ở đó giá trị của loss là nhỏ nhất (global minmum). Do vậy việc đi tìm các weight này còn được gọi là quá trình Optimization (tối ưu hóa). Ở cấp 3 chúng ta đã được biết là muốn tìm điểm mà hàm số $f(\theta)$ đạt giá trị nhỏ nhất thì ta tính đạo hàm $f$ theo $\theta$ rồi cho nó bằng 0 để tìm ra các điểm $\theta$ mà hàm đạt cực trị, sau đó ta sẽ so sánh giá trị của $f$ tại các cực trị này để tìm ra điểm cho giá trị nhỏ nhất. Cũng tương tự như vậy, để tìm global minimum của $L$ ta cũng có thể tính đạo hàm của $L$ theo $W$ rồi cho nó bằng 0 để tìm ra các $W$ với $L$ đạt cực trị rồi so sánh. Tuy nhiên trên thực tế việc giải hệ phương trình với số biến $w$ như mạng ANN đơn giản của chúng ta đã là một điều không hề đơn giản, chưa nói đến các ANN phức tạp hơn. Vì vậy để optimized các weight $w$ chúng ta sẽ dựa vào một thuật toán optimization gọi là Gradient Descent (GD). <br/>
Nguyên lý cơ bản của GD dựa trên việc nếu ta biết được đạo hàm của một hàm số $f$ theo một biến $\theta$ tại một điểm nào đó thì ta biết được $f(\theta)$ sẽ tăng hay là giảm bao nhiêu nếu $\theta$ tăng hoặc giảm một lượng nhỏ từ điểm đó (các bạn chưa hiểu có thể tham khảo [link](https://tuoitre.vn/nhung-bi-an-trong-toan-pho-thong-dao-ham-de-lam-gi-2017101215393784.htm)). Nếu đạo hàm $df(\theta)>0$ tại một điểm $\theta_0$ thì ta biết rằng nếu ta giảm $\theta=\theta_0-\epsilon$ với $\epsilon$ rất nhỏ thì $f(\theta)$ cũng sẽ giảm một lượng là $df(\theta_0)*\epsilon$ và ngược lại. Còn nếu $df(\theta_0)<0$ thì tại điểm $\theta_0$, $f(\theta)$ sẽ giảm khi ta tăng $\theta$ và ngược lại. Nói cách khác, nếu đạo hàm là dương thì $f$ tăng cùng chiều với $\theta$ còn đạo hàm âm thì $f$ tăng ngược chiều với $\theta$. Do đo đối với mạng ANN của chúng ta nếu ta biết đạo hàm $\partial L/ \partial w_{jk}^{(l)}$ của loss $L$ theo weight $w_{jk}^{(l)}$ tại một giá trị $w_{jk}^{(l)}=w_0$ nào đó thì ta biết rằng nếu tăng $w_{jk}^{(l)}$ ngược với dấu của giá trị đạo hàm tại $w_0$ thì giá trị của $L$ sẽ giảm.<br/>
Tổng hợp lại thì để optimize một MLP với softmax cross entropy loss dùng thuật toán Gradient Descent với dataset có chứa các cặp input và label $(X, Y)$ thì ta sẽ thực hiện lần lượt các bước như sau:<br/>
1. Tạo ngẫu nhiên các giá trị của các weight $W=W_0$
2. Tính giá trị của output $\hat{Y}$ từ input $X$ và $W$ như [mục 3](#forward).
3. Tính giá trị của loss $L(W)$ từ $\hat{Y}$ và $Y$ như [mục 4.1](#loss).
4. Tính từng đạo hàm $\partial L/\partial w_{jk}^{(l)}$.
5. Update giá trị của từng weight ngược hướng với đạo hàm một lượng nhỏ để giảm $L$:<br/>
$w_{jk}^{(l)} = w_{jk}^{(l)} + \alpha*\partial L/\partial w_{jk}^{(l)}$.
6. Lặp lại bước 2 với data kế tiếp cho tới khi $L$ không giảm nữa.

Ở đây $\alpha$ được gọi là **learning rate** vì nó quyết định sự thay đổi hay là học (learn) của các weight tại mỗi lần update. Bằng cách lặp đi lặp lại quá trình này ta hi vọng sẽ tìm được giá trị tối ưu $W^{\ast}$. Trên thực tế đối với các Deep Neural Network với quá nhiều weight thì ta thường không có cách nào tìm được điểm global minimum mà phải an phận với một trong các local minimum (điểm cực tiểu). May mắn là các điểm local minimum này thường đủ tốt cho các bài toán mà chúng ta gặp phải. Trong áp dụng thực tế thì ta cần biết nhiều kĩ thuật liên quan đến Weight Initializaion, Regularization cũng như việc chọn learning rate để giúp thuật toán GD tìm được một điểm local minimum tốt dễ dàng hơn mà nếu có dịp nhóm sẽ tiếp tục giới thiệu trong các bài viết sau. Còn một điểm quan trọng nữa chưa được nhắc đến trong bài viết này là chúng ta vẫn chưa biết được cách tìm các đạo hàm trong bước 4. Đó chính là phương pháp **Backpropagation** mà chắc hẳn các bạn quan tâm đến DL đã từng nghe nói tới nhiều. Do thời lượng của bài viết này đã dài nên nhóm xin phép được giới thiệu về backprobagation trong bài viết tới.     




